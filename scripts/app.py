import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase
import av
import cv2
import easyocr
import numpy as np
from PIL import Image
import re

st.set_page_config(page_title="ãƒ©ãƒ™ãƒ«ã‚¹ã‚­ãƒ£ãƒŠ ãƒœã‚¿ãƒ³ç‰ˆ", layout="centered")
st.title("ğŸ“· ãƒ©ãƒ™ãƒ«ã‚¹ã‚­ãƒ£ãƒŠï¼ˆã‚¹ã‚­ãƒ£ãƒ³ãƒœã‚¿ãƒ³ã§OCRï¼‰")

# ===== OCRèª¤èªè£œæ­£ãƒãƒƒãƒ— =====
OCR_CORRECTION = {
    "ä¸€":"-",
    "O":"0", "0":"O", "å·´":"B",
    "|":"|", "ï½œ":"|",
    "ï¼ˆ":"(", "ï¼‰":")"
}

# ===== OCRé–¢æ•° =====
def ocr_image(pil_img):
    reader = easyocr.Reader(['ja', 'en'], gpu=False)
    img = np.array(pil_img)
    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)

    # 2å€ãƒªã‚µã‚¤ã‚ºã—ã¦æ–‡å­—å¼·èª¿
    h, w = gray.shape
    gray_resized = cv2.resize(gray, (w*2, h*2), interpolation=cv2.INTER_CUBIC)

    # Adaptive Threshold
    th = cv2.adaptiveThreshold(
        gray_resized, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        11, 10
    )

    # OCRå®Ÿè¡Œ
    results = reader.readtext(th, detail=1)
    texts = []
    for bbox, text, conf in results:
        if conf > 0.5:
            corrected = ''.join([OCR_CORRECTION.get(c, c) for c in text])
            texts.append(corrected)

    # æ–‡å­—çµåˆï¼‹è‹±æ•°å­—ã¨ãƒã‚¤ãƒ•ãƒ³ã®ã¿æŠ½å‡º
    joined = ''.join(texts)
    joined = re.sub(r'[^A-Za-z0-9\-]', '', joined)
    return joined

# ===== ãƒ©ãƒ™ãƒ«è‰²åˆ¤å®š =====
def detect_label_color(pil_img):
    img = np.array(pil_img)
    avg_color = np.mean(img, axis=(0, 1))
    brightness = np.mean(avg_color)
    return "ç™½" if brightness > 190 else "é€æ˜"

# ===== ã‚«ãƒ¡ãƒ©æ˜ åƒå‡¦ç† =====
class FrameProcessor(VideoProcessorBase):
    latest_frame = None

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        h, w, _ = img.shape

        # æ ç·šã‚µã‚¤ã‚ºï¼ˆæ¨ª8cm Ã— ç¸¦1.5cmç›®å®‰ï¼‰
        px_per_cm = 37.795
        rect_w = int(8 * px_per_cm)
        rect_h = int(1.5 * px_per_cm)
        rect_w = min(rect_w, w-10)
        rect_h = min(rect_h, h-10)
        x1 = (w - rect_w) // 2
        y1 = (h - rect_h) // 2
        x2 = x1 + rect_w
        y2 = y1 + rect_h

        # æ ç·šæç”»
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)

        # æ å†…ç”»åƒä¿æŒ
        self.latest_frame = img[y1:y2, x1:x2].copy()

        return av.VideoFrame.from_ndarray(img, format="bgr24")

# ===== Streamlit UI =====
st.info("ğŸ“¸ ã‚«ãƒ¡ãƒ©èµ·å‹•ä¸­ï¼šä¸­å¤®ã®æ ã«ãƒ©ãƒ™ãƒ«ã‚’ã‹ã–ã—ã¦ã€Œã‚¹ã‚­ãƒ£ãƒ³ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„")

webrtc_ctx = webrtc_streamer(
    key="label-scanner",
    video_processor_factory=FrameProcessor,
    media_stream_constraints={"video": True, "audio": False},
)

# ===== ã‚¹ã‚­ãƒ£ãƒ³ãƒœã‚¿ãƒ³ =====
if webrtc_ctx.video_processor:
    if st.button("ğŸ” ã‚¹ã‚­ãƒ£ãƒ³"):
        frame = webrtc_ctx.video_processor.latest_frame
        if frame is not None:
            pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

            # OCR + ãƒ©ãƒ™ãƒ«è‰²åˆ¤å®š
            texts = ocr_image(pil_img)
            color = detect_label_color(pil_img)

            st.image(pil_img, caption="ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡", use_container_width=True)
            st.success("âœ… ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†ï¼")
            st.write(f"ğŸˆ¶ OCRçµæœ: {texts}")
            st.write(f"ğŸ¨ ãƒ©ãƒ™ãƒ«è‰²: {color}")
        else:
            st.warning("â— æ å†…ç”»åƒãŒã¾ã å–å¾—ã§ãã¦ã„ã¾ã›ã‚“ã€‚")
